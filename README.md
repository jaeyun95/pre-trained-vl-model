## Pretrained model summary   
* ### [pretrained language model](#pretrained-language-model)   
* ### [pretrained vision model](pretrained-vision-model)   
* ### [pretrained vision and language model](pretrained-vision-and-language-model)   
---
## Pretrained language model   
* Improving Language Understanding by Generative Pre-Training[[paper]](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)[[code]](https://github.com/huggingface/transformers)   
* ELMo : Deep contextualized word representations[[paper]](https://arxiv.org/pdf/1802.05365.pdf)[[code]](https://github.com/yuanxiaosc/ELMo)   
* BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding[[paper]](https://arxiv.org/pdf/1810.04805.pdf)[[code(tensorflow)]](https://github.com/google-research/bert)[[code(pytorch)]](https://github.com/codertimo/BERT-pytorch)   
* ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS[[paper]](https://arxiv.org/pdf/1909.11942.pdf)[[code(tensorflow)]](https://github.com/google-research/albert)[[code(pytorch)]](https://github.com/graykode/ALBERT-Pytorch)   
* RoBERTa: A Robustly Optimized BERT Pretraining Approach[[paper]](https://arxiv.org/pdf/1907.11692.pdf)[[code]](https://github.com/pytorch/fairseq/tree/master/examples/roberta)   
* Language Models are Unsupervised Multitask Learners[[paper]](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)[[code]](https://github.com/openai/gpt-2)   
* Language Models are Few-Shot Learners[[paper]](https://arxiv.org/pdf/2005.14165.pdf)[[code]](https://github.com/openai/gpt-3)   
* XLNet: Generalized Autoregressive Pretraining for Language Understanding[[paper]](https://arxiv.org/pdf/1906.08237.pdf)[[code]](https://github.com/zihangdai/xlnet)   
---
## Pretrained vision model   
* Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks[[paper]](https://arxiv.org/pdf/1506.01497.pdf)[[code]](https://github.com/rbgirshick/py-faster-rcnn)   
* Mask R-CNN[[paper]](https://arxiv.org/pdf/1703.06870.pdf)[[code]](https://github.com/matterport/Mask_RCNN)   


---
## Pretrained vision and language model   

